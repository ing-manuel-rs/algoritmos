# **Algoritmos probabilísticos y aproximados**

Son algoritmos que utilizan aleatoriedad o devuelven soluciones aproximadas, pero en un tiempo razonable y con alta probabilidad de ser correctos.



## Clasificación general

#### Algoritmos Probabilísticos (Randomized)

Usan aleatoriedad interna para tomar decisiones. Pueden:
- Ser correctos con cierta probabilidad
- Tener mejor rendimiento en promedio
- Ser más simples que sus equivalentes deterministas

Ejemplos:
- QuickSort aleatorizado
- Primalidad de Miller-Rabin
- Hashing universal
- Algoritmo de Monte Carlo


#### Algoritmos Aproximados

No devuelven una solución exacta, sino una cercana, pero mucho más rápido.

Ejemplos:
- Set Cover, Vertex Cover aproximado
- Algoritmo de PageRank (web)
- K-Means (agrupamiento)
- Local search heuristics



## Diferencias clave

|Tipo|Usa azar|Puede fallar|Resultado exacto|
|---|---|---|---|
|Determinista|❌|❌|✔️|
|Probabilístico|✔️|✔️ (bajo p)|✔️ (con p alta)|
|Aproximado|❌ o ✔️|❌|❌|



## Ejemplo 1: Miller-Rabin (Prueba de primalidad)

Prueba si un número `n` es primo con probabilidad alta.
```js
function isProbablyPrime(n, k = 5) {
  if (n < 2) return false;
  if (n === 2 || n === 3) return true;
  if (n % 2 === 0) return false;

  let s = 0;
  let d = n - 1;
  while (d % 2 === 0) {
    d /= 2;
    s += 1;
  }

  WitnessLoop: for (let i = 0; i < k; i++) {
    const a = BigInt(2 + Math.floor(Math.random() * (n - 4)));
    let x = modExp(a, d, n);
    if (x === 1 || x === n - 1) continue;

    for (let r = 0; r < s - 1; r++) {
      x = modExp(x, 2, n);
      if (x === n - 1) continue WitnessLoop;
    }

    return false; // compuesto
  }

  return true; // probablemente primo
}

function modExp(base, exp, mod) {
  base = BigInt(base);
  exp = BigInt(exp);
  mod = BigInt(mod);
  let result = 1n;

  while (exp > 0) {
    if (exp % 2n === 1n) result = (result * base) % mod;
    base = (base * base) % mod;
    exp /= 2n;
  }

  return result;
}
```
Corre en tiempo `O(k·log³ n)`  
Tiene riesgo de error controlado por `k`



## Ejemplo 2: Algoritmo de Monte Carlo (Estimación de π)

```js
function estimarPI(iteraciones = 1000000) {
  let dentro = 0;
  for (let i = 0; i < iteraciones; i++) {
    const x = Math.random();
    const y = Math.random();
    if (x * x + y * y <= 1) dentro++;
  }
  return (4 * dentro) / iteraciones;
}
```
A mayor `n`, mejor precisión  
Probabilístico, no garantiza exactitud



## Ejemplo 3: K-Means Clustering (aproximado)

Agrupa puntos cercanos. No garantiza la mejor partición, pero es eficiente.
```js
function kMeans(puntos, k, iteraciones = 100) {
  const centroides = puntos.slice(0, k);
  for (let i = 0; i < iteraciones; i++) {
    const clusters = Array.from({ length: k }, () => []);

    puntos.forEach((p) => {
      let idxMin = 0;
      let minDist = Infinity;
      centroides.forEach((c, idx) => {
        const dist = Math.hypot(p[0] - c[0], p[1] - c[1]);
        if (dist < minDist) {
          minDist = dist;
          idxMin = idx;
        }
      });
      clusters[idxMin].push(p);
    });

    for (let j = 0; j < k; j++) {
      if (clusters[j].length > 0) {
        const sumX = clusters[j].reduce((sum, p) => sum + p[0], 0);
        const sumY = clusters[j].reduce((sum, p) => sum + p[1], 0);
        centroides[j] = [sumX / clusters[j].length, sumY / clusters[j].length];
      }
    }
  }
  return centroides;
}
```
Solución aproximada en `O(nkt)`  
No garantiza el óptimo global



## Aplicaciones reales

- Google, Facebook: Bloom Filters para URLs visitadas
- Netflix: K-Means para clusters de usuarios
- Criptografía: Miller-Rabin, primalidad
- Bioinformática: alineamiento de genes (aproximado)
- Motores de búsqueda: hashing y conteo probabilístico



## Ventajas

- Muy rápidos en big data
- Más simples que los deterministas exactos
- Ideales para problemas sin solución exacta eficiente



## Desventajas

- Pueden fallar o ser inexactos
- Requieren análisis probabilístico para asegurar calidad
- Difíciles de depurar y testear con precisión

